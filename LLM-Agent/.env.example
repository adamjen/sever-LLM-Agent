# --- LLM Agent Configuration ---

# The full URL for the agent's FastAPI service (used by the CLI)
AGENT_API_URL=http://127.0.0.1:8000/api/v1/agent

# The endpoint for the LLM's chat completions API (e.g., LM Studio, OpenAI)
LM_STUDIO_ENDPOINT=http://localhost:1234/v1/chat/completions

# The model identifier to be used for the LLM API call.
# Example for LM Studio: "gemma-2b-it-q8_0.gguf"
LM_STUDIO_MODEL=local-model

# The path to the compiled SIRS engine executable.
SIRS_EXECUTABLE_PATH=./sirs_engine